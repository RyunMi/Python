{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<!DOCTYPE html>\n<html lang=\"cn\">\n<head>\n\t<meta charset=\"UTF-8\">\n\t<title>Scraping tutorial 1 | 莫烦Python</title>\n\t<link rel=\"icon\" href=\"{{ site_url }}/static/img/description/tab_icon.png\">\n</head>\n<body>\n\t<h1>爬虫测试1</h1>\n\t<p>\n\t\t这是一个在 <a href=\"{{ site_url }}/\">莫烦Python</a>\n\t\t<a href=\"{{ site_url }}/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n\t</p>\n\n</body>\n</html>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# if has Chinese, apply decode()\n",
    "html = urlopen(\"https://mofanpy.com/static/scraping/basic-structure.html\").read().decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nPage title is:  Scraping tutorial 1 | 莫烦Python\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "res = re.findall(r\"<title>(.+?)</title>\", html)\n",
    "print(\"\\nPage title is: \", res[0])\n",
    "# Page title is:  Scraping tutorial 1 | 莫烦Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nPage paragraph is:  \n\t\t这是一个在 <a href=\"{{ site_url }}/\">莫烦Python</a>\n\t\t<a href=\"{{ site_url }}/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n\t\n"
     ]
    }
   ],
   "source": [
    "res = re.findall(r\"<p>(.*?)</p>\", html, flags=re.DOTALL)    # re.DOTALL if multi line\n",
    "print(\"\\nPage paragraph is: \", res[0])\n",
    "# Page paragraph is:\n",
    "#     这是一个在 <a href=\"https://mofanpy.com/\">莫烦Python</a>\n",
    "#     <a href=\"https://mofanpy.com/tutorials/scraping\">爬虫教程</a> 中的简单测试."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nAll links:  ['{{ site_url }}/static/img/description/tab_icon.png', '{{ site_url }}/', '{{ site_url }}/tutorials/data-manipulation/scraping/']\n"
     ]
    }
   ],
   "source": [
    "res = re.findall(r'href=\"(.*?)\"', html)\n",
    "print(\"\\nAll links: \", res)\n",
    "# All links:  ['https://mofanpy.com/static/img/description/tab_icon.png', 'https://mofanpy.com/', 'https://mofanpy.com/tutorials/scraping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<!DOCTYPE html>\n<html lang=\"cn\">\n<head>\n\t<meta charset=\"UTF-8\">\n\t<title>Scraping tutorial 1 | 莫烦Python</title>\n\t<link rel=\"icon\" href=\"{{ site_url }}/static/img/description/tab_icon.png\">\n</head>\n<body>\n\t<h1>爬虫测试1</h1>\n\t<p>\n\t\t这是一个在 <a href=\"{{ site_url }}/\">莫烦Python</a>\n\t\t<a href=\"{{ site_url }}/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n\t</p>\n\n</body>\n</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# if has Chinese, apply decode()\n",
    "html = urlopen(\"https://mofanpy.com/static/scraping/basic-structure.html\").read().decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<h1>爬虫测试1</h1>\n\n <p>\n\t\t这是一个在 <a href=\"{{ site_url }}/\">莫烦Python</a>\n<a href=\"{{ site_url }}/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n\t</p>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, features='lxml')\n",
    "print(soup.h1)\n",
    "print('\\n', soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<a href=\"{{ site_url }}/\">莫烦Python</a>, <a href=\"{{ site_url }}/tutorials/data-manipulation/scraping/\">爬虫教程</a>]\n\n ['{{ site_url }}/', '{{ site_url }}/tutorials/data-manipulation/scraping/']\n"
     ]
    }
   ],
   "source": [
    "all_href = soup.find_all('a')\n",
    "print(all_href)\n",
    "all_href = [l['href'] for l in all_href]\n",
    "print('\\n', all_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# if has Chinese, apply decode()\n",
    "html = urlopen(\"https://mofanpy.com/static/scraping/list.html\").read().decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "一月\n二月\n三月\n四月\n五月\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, features='lxml')\n",
    "\n",
    "# use class to narrow search\n",
    "month = soup.find_all('li', {\"class\": \"month\"})\n",
    "for m in month:\n",
    "    print(m.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n<tr>\n<th>\n\t\t\t分类\n\t\t</th><th>\n\t\t\t名字\n\t\t</th><th>\n\t\t\t时长\n\t\t</th><th>\n\t\t\t预览\n\t\t</th>\n</tr>\n\n\n<tr class=\"ml\" id=\"course1\">\n<td>\n\t\t\t机器学习\n\t\t</td><td>\n<a href=\"/tutorials/machine-learning/tensorflow/\">\n\t\t\t\tTensorflow 神经网络</a>\n</td><td>\n\t\t\t2:00\n\t\t</td><td>\n<img src=\"/static/img/course_cover/tf.jpg\"/>\n</td>\n</tr>\n\n\n<tr class=\"ml\" id=\"course2\">\n<td>\n\t\t\t机器学习\n\t\t</td><td>\n<a href=\"/tutorials/machine-learning/reinforcement-learning/\">\n\t\t\t\t强化学习</a>\n</td><td>\n\t\t\t5:00\n\t\t</td><td>\n<img src=\"/static/img/course_cover/rl.jpg\"/>\n</td>\n</tr>\n\n\n<tr class=\"data\" id=\"course3\">\n<td>\n\t\t\t数据处理\n\t\t</td><td>\n<a href=\"/tutorials/data-manipulation/scraping/\">\n\t\t\t\t爬虫</a>\n</td><td>\n\t\t\t3:00\n\t\t</td><td>\n<img src=\"/static/img/course_cover/scraping.jpg\"/>\n</td>\n</tr>\n\n\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# if has Chinese, apply decode()\n",
    "html = urlopen(\"https://mofanpy.com/static/scraping/table.html\").read().decode('utf-8')\n",
    "\n",
    "soup = BeautifulSoup(html, features='lxml')\n",
    "\n",
    "# print with title\n",
    "for item in soup.find(\"table\", {\"id\": \"course-list\"}).children:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------------\n\n\n<tr class=\"ml\" id=\"course1\">\n<td>\n\t\t\t机器学习\n\t\t</td><td>\n<a href=\"/tutorials/machine-learning/tensorflow/\">\n\t\t\t\tTensorflow 神经网络</a>\n</td><td>\n\t\t\t2:00\n\t\t</td><td>\n<img src=\"/static/img/course_cover/tf.jpg\"/>\n</td>\n</tr>\n\n\n<tr class=\"ml\" id=\"course2\">\n<td>\n\t\t\t机器学习\n\t\t</td><td>\n<a href=\"/tutorials/machine-learning/reinforcement-learning/\">\n\t\t\t\t强化学习</a>\n</td><td>\n\t\t\t5:00\n\t\t</td><td>\n<img src=\"/static/img/course_cover/rl.jpg\"/>\n</td>\n</tr>\n\n\n<tr class=\"data\" id=\"course3\">\n<td>\n\t\t\t数据处理\n\t\t</td><td>\n<a href=\"/tutorials/data-manipulation/scraping/\">\n\t\t\t\t爬虫</a>\n</td><td>\n\t\t\t3:00\n\t\t</td><td>\n<img src=\"/static/img/course_cover/scraping.jpg\"/>\n</td>\n</tr>\n\n\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\")\n",
    "# print without title\n",
    "for item in soup.find(\"table\", {\"id\": \"course-list\"}).tr.next_siblings:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------------\n\n\t\t\t3:00\n\t\t\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\")\n",
    "# navigate using next_sibling/previous_sibling\n",
    "print(soup.find(\"img\", {\"src\": \"/static/img/course_cover/scraping.jpg\"}).parent.previous_sibling.get_text())"
   ]
  }
 ]
}